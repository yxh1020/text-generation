{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small-text-generation-word.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTbJqGFwbrjR",
        "colab_type": "text"
      },
      "source": [
        "# Mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhHxl4ivpe6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow--gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwnv_eEbhpz",
        "colab_type": "code",
        "outputId": "229c1890-8d3a-4e90-d06d-9e4103e153f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtzEwxVRcxUk",
        "colab_type": "text"
      },
      "source": [
        "# Load modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiUyYUWdcw9u",
        "colab_type": "code",
        "outputId": "bf032f59-6293-46aa-ae36-ce298d819b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import unicodedata\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTCMZpr7cAga",
        "colab_type": "text"
      },
      "source": [
        "# Load and explore data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9DMvOFRbvhL",
        "colab_type": "code",
        "outputId": "26965385-f5f8-48d1-d7d1-460b0635ade1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/text-generation/text-generation-word/nips.csv')\n",
        "df = df[df['Abstract'] != \"Abstract Missing\"]\n",
        "df = df.reset_index(drop=True)\n",
        "df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4933 entries, 0 to 4932\n",
            "Data columns (total 3 columns):\n",
            "Year        4933 non-null int64\n",
            "Title       4933 non-null object\n",
            "Abstract    4933 non-null object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 115.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrmLuvAExrV-",
        "colab_type": "code",
        "outputId": "24c46170-4306-4e38-b26a-96d1f3f71b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# Select a small dataset\n",
        "df_small = df.iloc[:1500]\n",
        "df_small.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1500 entries, 0 to 1499\n",
            "Data columns (total 3 columns):\n",
            "Year        1500 non-null int64\n",
            "Title       1500 non-null object\n",
            "Abstract    1500 non-null object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 35.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwOrFDY0CpQF",
        "colab_type": "code",
        "outputId": "50e036d0-5db3-4fbc-a5ba-46c5a0e30843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "text = df_small['Abstract']\n",
        "text.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Up-\u0002propagation is an algorithm for inverting ...\n",
              "1    We have constructed an inexpensive video based...\n",
              "2    Non-negative matrix factorization (NMF) has pr...\n",
              "3    Spike-triggered averaging techniques are effec...\n",
              "4    We consider continuous state, continuous actio...\n",
              "Name: Abstract, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVYcaJm_cvJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_text(index, Series):\n",
        "    example = Series[Series.index == index].values[0]\n",
        "    if len(example) > 0:\n",
        "        print(example)\n",
        "    else:\n",
        "      print('Empty!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT2SHfaBxbOt",
        "colab_type": "code",
        "outputId": "d431a1ad-5f98-473b-b941-5e4d8e8b7544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "print_text(0,text)\n",
        "print_text(10,text)\n",
        "print_text(20, text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Up-\u0002propagation is an algorithm for inverting and learning neural network\r\n",
            "generative models\u0003 Sensory input is processed by inverting a model that\r\n",
            "generates patterns from hidden variables using top\u0002down connections\u0003\r\n",
            "The inversion process is iterative\u0004 utilizing a negative feedback loop that\r\n",
            "depends on an error signal propagated by bottom\u0002up connections\u0003 The\r\n",
            "error signal is also used to learn the generative model from examples\u0003\r\n",
            "The algorithm is benchmarked against principal component analysis in\r\n",
            "experiments on images of handwritten digits\u0003.\n",
            "Computational models of visual cortex, and in particular those based on sparse coding, have enjoyed much recent attention. Despite this currency, the question of how sparse or how over-complete a sparse representation should be, has gone without principled answer. Here, we use Bayesian model-selection methods to address these questions for a sparse-coding model based on a Student-t prior. Having validated our methods on toy data, we find that natural images are indeed best modelled by extremely sparse distributions; although for the Student-t prior, the associated optimal basis size is only modestly overcomplete.\n",
            "Under natural viewing conditions, human observers shift their gaze to allocate processing resources to subsets of the visual input. Many computational models have aimed at predicting such voluntary attentional shifts. Although the importance of high level stimulus properties (higher order statistics, semantics) stands undisputed, most models are based on low-level features of the input alone. In this study we recorded eye-movements of human observers while they viewed photographs of natural scenes. About two thirds of the stimuli contained at least one person. We demonstrate that a combined model of face detection and low-level saliency clearly outperforms a low-level model in predicting locations humans fixate. This is reflected in our finding fact that observes, even when not instructed to look for anything particular, fixate on a face with a probability of over 80% within their first two fixations (500ms). Remarkably, the model's predictive performance in images that do not contain faces is not impaired by spurious face detector responses, which is suggestive of a bottom-up mechanism for face detection. In summary, we provide a novel computational approach which combines high level object knowledge (in our case: face locations) with low-level features to successfully predict the allocation of attentional resources.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En7K7yeFXnXw",
        "colab_type": "code",
        "outputId": "5aba6d93-3e58-43d5-b81b-f636dd48d63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "corpus_init = ' '.join(list(text))\n",
        "words_init = corpus_init.split()\n",
        "n_words_init = len(words_init)\n",
        "unique_words_init = sorted(list(set(words_init)))\n",
        "n_unique_words_init = len(unique_words_init)\n",
        "print(\"Total number of words before text preprocessing:\", n_words_init)\n",
        "print(\"Total number of unique words before text preprocessing: \", n_unique_words_init)\n",
        "print(unique_words_init[:100])\n",
        "print(unique_words_init[100:200])\n",
        "print(unique_words_init[200:300])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words before text preprocessing: 212975\n",
            "Total number of unique words before text preprocessing:  19055\n",
            "['\"DUOL\"', '\"Expansion-Constrained', '\"Generalized', '\"Hedge\"', '\"autotags\")', '\"averagers,\"', '\"chill\"', '\"disagreement', '\"disappearance\"', '\"expected', '\"external\"', '\"functional', '\"human-like\"', '\"internal\"', '\"isotropic\"', '\"jogging\"', '\"local', '\"missingness\"', '\"naive\"', '\"no\"', '\"nonlinearity\"', '\"shared', '\"simple', '\"skeleton\"', '\"smoothed', '#P', '#P-hard', '$', '$(+\\\\!3,', '$(0,\\\\pi/2]$.', '$(1+(1+\\\\epsilon)\\\\gamma)$-approximate', '$(1+\\\\alpha)\\\\,L^*_\\\\gamma', '$(1+\\\\eps)$', '$(1+\\\\eps)$-approximation', '$(2,', '$(2,1)$-norm', '$(3,', '$(Christopher,', '$(X_1,', '$(\\\\alpha,', '$(\\\\beta,B)$-Bernstein,', '$(has\\\\_husband,', '$(m\\\\gg', '$(x_k)_{k=0}^K$,', '$(x_k)_{k=1}^K$', '$(y_k', '$+$', '$+1$', '$+1/\\\\sqrt{t}$', '$+\\\\!3$', '$-1$', '$-1/\\\\sqrt{t}$', '$0$', '$1', '$1$', '$1$-norm', '$1$.', '$1)$', '$1,', '$1,\\\\infty$', '$1,\\\\infty$-regularized', '$1-\\\\alpha_i$', '$1/\\\\epsilon$', '$1/\\\\epsilon$.', '$10^{64}$', '$10^{70}$', '$11\\\\%$', '$14\\\\%$', '$14\\\\epsilon', '$1\\\\leq', '$2)$', '$2+\\\\eps$.', '$2\\\\sqrt{T}e^{-\\\\epsilon^2', '$2^d$', '$2n\\\\ln', '$30$', '$500$', '$512', '$66\\\\%$', '$95$\\\\%', '$98.1\\\\%$', '$A', '$A$', '$A_k$', '$C$', '$C(P)$', '$C(P)\\\\log', '$C(s-N)^{1/p}\\\\sqrt{\\\\log', '$C_L$', '$Cs^{1/p}\\\\sqrt{\\\\log', '$D$', '$D_i$', '$G', '$G$', '$G(n,\\\\frac{1}{2})$.', '$G(x)$', '$H\\\\subset', '$I_{\\\\rho_t}(S;A)', '$I_{\\\\rho_t}(S;A)$', '$K$']\n",
            "['$K$-CV,', '$K$-dimensional', '$K$-fold', '$K$-sparse', '$K$th-order', '$K<M\\\\ll', '$KL$', '$L^*_\\\\gamma$', '$L_1$', '$L_1$-norm.', '$L_1$-regularization', '$L_2$', '$L_\\\\infty$-norm', '$L_p$', '$L_p$-nested', '$L_p$-norms', '$L_p$-norms.', '$L_p$-spherically', '$L_p${\\\\em', '$M$', '$M$-estimators', '$N$', '$N$,', '$N(0,\\\\sigma^2I)$,', '$N=s$,', '$N\\\\approx', '$N^2$', '$O(1', '$O(1/\\\\epsilon)$', '$O(1/\\\\epsilon^{2})$', '$O(1/\\\\sqrt{T})$', '$O(1/\\\\sqrt{\\\\epsilon})$', '$O(1/\\\\sqrt{\\\\varepsilon})$.', '$O(1/\\\\sqrt{n})$.', '$O(1/n)$', '$O(1/n)$.', '$O(B\\\\theta', '$O(D^3\\\\log^2', '$O(D^{2+\\\\delta})$', '$O(D^{2})$).', '$O(N^{-0.5+\\\\eps})$', '$O(N^{-0.5})$.', '$O(T^{-1})$.', '$O(T^{-{\\\\gamma}/{d}})$,', '$O(T^{1/2}\\\\log', '$O(T^{2/3}', '$O(\\\\eps)$', '$O(\\\\frac{1}{N}+\\\\exp\\\\{-N\\\\})$', '$O(\\\\frac{1}{N}+\\\\frac{1}{N^2})$', '$O(\\\\frac{\\\\log', '$O(\\\\frac{k^2}{\\\\eps^2}', '$O(\\\\frac{k}{\\\\eps^2}', '$O(\\\\ln', '$O(\\\\log', '$O(\\\\poly(d)\\\\sqrt{T})$', '$O(\\\\sqrt{\\\\eps})$.', '$O(\\\\sqrt{n(\\\\log', '$O(dk^3/\\\\eps^2)$', '$O(k-1)', '$O(m^{1/3}\\\\sqrt{ln', '$O(n', '$O(n)$', '$O(n+', '$O(n\\\\log^2n/\\\\log(2D))$', '$O(n\\\\poly(\\\\log', '$O(n^2)$', '$O(n^3)$', '$O(n^{-\\\\frac{\\\\alpha}{1+\\\\alpha}})$,', '$O(p^2)$', '$O(rn^2)$,', '$O\\\\left(\\\\frac{k}{\\\\eps^2}\\\\left(\\\\min\\\\left(k,', '$R$', '$R$-nearest', '$R^d$.', '$S', '$S$', '$SVM-\\\\theta$', '$S_1$),', '$S_k$', '$S_k$---we', '$S_k$-sparse', '$T', '$T$', '$T$.', '$U(\\\\theta)$', '$U(\\\\theta)$,', '$V$', '$X', '$X$', '$X$.', '$X=x$', '$X\\\\in', '$Y$', '$Y$.', '$Y_T$', '$Y_T$.', '$Z$', '$Z$.', '$\\\\Delta', '$\\\\Delta$']\n",
            "['$\\\\Hilb$', '$\\\\Hilb$.', '$\\\\Hilb$;', '$\\\\LTP$', '$\\\\LowerRateSq', '$\\\\LowerRateSq$', '$\\\\MO$($n^2$)', '$\\\\MO$($np/m$),', '$\\\\MO$($np^2/m$).', '$\\\\Omega', '$\\\\Omega(D\\\\log', '$\\\\Omega(N^2)$', '$\\\\Omega(\\\\sqrt{T})$', '$\\\\Omega(k', '$\\\\Omega(k\\\\log(n-k))$', '$\\\\Omega(p)$', '$\\\\R^d$,', '$\\\\R^d$.', '$\\\\R^n$', '$\\\\R^n$.', '$\\\\R^n_+$.', '$\\\\Real^d$,', '$\\\\Sigma$', '$\\\\Sigma$:', '$\\\\SobM$', '$\\\\Theta$', '$\\\\Theta(\\\\ln', '$\\\\Theta(\\\\sum_{i}D_{i}^{2})$', '$\\\\Theta(k', '$\\\\Theta(n)$', '$\\\\Theta({\\\\sqrt{n}})$', '$\\\\a$-mixing', '$\\\\alpha', '$\\\\alpha$', '$\\\\alpha$-divergence', '$\\\\alpha$-expansion', '$\\\\alpha,\\\\epsilon$,', '$\\\\alpha=0$.', '$\\\\alpha_i$', '$\\\\auc$', '$\\\\beta', '$\\\\beta$-divergences.', '$\\\\beta$.', '$\\\\beta^*$', '$\\\\beta^*$,', '$\\\\beta^*$.', '$\\\\beta^{\\\\star}$', '$\\\\bx$,', '$\\\\cH$', '$\\\\chi^2$', '$\\\\de$', '$\\\\delta$', '$\\\\delta>0$', '$\\\\dim$', '$\\\\dot{\\\\Theta}$', '$\\\\dot{\\\\Theta}$,', '$\\\\ell$', '$\\\\ell_0$', '$\\\\ell_0$-type', '$\\\\ell_1$', '$\\\\ell_1$,', '$\\\\ell_1$-based', '$\\\\ell_1$-norm', '$\\\\ell_1$-norm),', '$\\\\ell_1$-penalized', '$\\\\ell_1$-penalty', '$\\\\ell_1$-regularization', '$\\\\ell_1$-regularized', '$\\\\ell_1$-regularizer).', '$\\\\ell_1$.', '$\\\\ell_1/\\\\ell_q$', '$\\\\ell_2$', '$\\\\ell_2$,', '$\\\\ell_2$-ball', '$\\\\ell_2^2$,', '$\\\\ell_\\\\infty$', '$\\\\ell_\\\\infty$-norms', '$\\\\ellnorm_p$', '$\\\\eps', '$\\\\eps$', '$\\\\eps$,', '$\\\\eps>0$', '$\\\\epsilon', '$\\\\epsilon$', '$\\\\epsilon$-decompositions', '$\\\\epsilon$-descent', '$\\\\epsilon$-optimal', '$\\\\epsilon$-pointwise', '$\\\\epsilon$.', '$\\\\eta$', '$\\\\eta$-function', '$\\\\eta$-function.', '$\\\\exp(-\\\\Theta)$', '$\\\\exp(\\\\cdot)$,', '$\\\\exp(\\\\tilde{O}(1/\\\\gamma))$.', '$\\\\frac{2\\\\gamma{(1-\\\\gamma)^2}\\\\epsilon$-optimal.', '$\\\\frac{2\\\\gamma}{1-\\\\gamma}\\\\epsilon$-optimal,', '$\\\\gamma$', '$\\\\gamma$-approximate', '$\\\\gamma$-discounted']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMYBkIVj8TaS",
        "colab_type": "text"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxwXnb1edrwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word != ',' or word != '.':\n",
        "          new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "          new_words.append(new_word)\n",
        "    return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvSSyr478sfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "  # noise removal\n",
        "  text = re.sub(r'\\bhttps?://\\w+.+[^ ]\\b', 'link', text) #replace url with link\n",
        "  text = re.sub(r'\\~\\\\cite\\{[^}]*\\}','',text) # remove cite in the format of \"~\\cite{DeSaOR16}\"\n",
        "  text = re.sub(r'\\[[^]]*\\]', '', text) # remove between square brackets\n",
        "  text = re.sub(r'\\([^)]*\\)', '', text) # remove between parentheses\n",
        "  text = re.sub(r'\\{[^)]*\\}', '', text) # remove between curly brackets\n",
        "  \n",
        "  # normalization\n",
        "  text = text.lower() # convert to lowercase text\n",
        "  text = re.sub(r'\\-',' ', text) # seperate words like 'video-related'\n",
        "  text = re.sub(r'[^a-zA-Z0-9\\s\\.\\,]', '', text) # remove punctuation \n",
        "  \n",
        "  text = re.sub(r'[-+]?\\d*\\.?\\d+', 'NUMBER', text) # replace numbers with \"NUMBER\"\n",
        "  text = re.sub(r'\\.{2,}', '', text) # remove '..','...'\n",
        "  text = re.sub(r'\\.', ' . ', text) # seperate '.' from text\n",
        "  text = re.sub(r'\\,' , ' , ', text) # seperate ',' from text\n",
        "  \n",
        " \n",
        "  text = ' '.join(remove_non_ascii(text.split())) # remove non-ascii words\n",
        "  text = re.sub(r'[\\w]*NUMBER[\\w]*', 'NUMBER', text) # replace anyword containing \"NUMBER\" with \"NUMBER\"\n",
        "  \n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ysyMqmZ83sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text.apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVDllxHGqBlb",
        "colab_type": "code",
        "outputId": "a955fe39-0b0d-4968-a242-7d162c410c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print_text(0,text)\n",
        "print_text(10,text)\n",
        "print_text(20, text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "up propagation is an algorithm for inverting and learning neural network generative models sensory input is processed by inverting a model that generates patterns from hidden variables using topdown connections the inversion process is iterative utilizing a negative feedback loop that depends on an error signal propagated by bottomup connections the error signal is also used to learn the generative model from examples the algorithm is benchmarked against principal component analysis in experiments on images of handwritten digits .\n",
            "computational models of visual cortex , and in particular those based on sparse coding , have enjoyed much recent attention . despite this currency , the question of how sparse or how over complete a sparse representation should be , has gone without principled answer . here , we use bayesian model selection methods to address these questions for a sparse coding model based on a student t prior . having validated our methods on toy data , we find that natural images are indeed best modelled by extremely sparse distributions although for the student t prior , the associated optimal basis size is only modestly overcomplete .\n",
            "under natural viewing conditions , human observers shift their gaze to allocate processing resources to subsets of the visual input . many computational models have aimed at predicting such voluntary attentional shifts . although the importance of high level stimulus properties stands undisputed , most models are based on low level features of the input alone . in this study we recorded eye movements of human observers while they viewed photographs of natural scenes . about two thirds of the stimuli contained at least one person . we demonstrate that a combined model of face detection and low level saliency clearly outperforms a low level model in predicting locations humans fixate . this is reflected in our finding fact that observes , even when not instructed to look for anything particular , fixate on a face with a probability of over NUMBER within their first two fixations . remarkably , the models predictive performance in images that do not contain faces is not impaired by spurious face detector responses , which is suggestive of a bottom up mechanism for face detection . in summary , we provide a novel computational approach which combines high level object knowledge with low level features to successfully predict the allocation of attentional resources .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eem9Mwd3YsbO",
        "colab_type": "code",
        "outputId": "7bd3355a-0f23-4f74-9a79-9a09f4d1551b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "text_list = list(text)\n",
        "corpus = ' '.join(text_list)\n",
        "words = corpus.split()\n",
        "n_words = len(words)\n",
        "unique_words = sorted(list(set(words)))\n",
        "n_unique_words = len(unique_words)\n",
        "print(\"Total number of words:\", n_words)\n",
        "print(\"Total number of unique words: \", n_unique_words)\n",
        "print(unique_words[:100])\n",
        "print(unique_words[100:200])\n",
        "print(unique_words[200:300])\n",
        "print(unique_words[300:400])\n",
        "print(unique_words[400:500])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words: 228147\n",
            "Total number of unique words:  8897\n",
            "[',', '.', 'NUMBER', 'a', 'aaai', 'aalen', 'aberrant', 'abilities', 'ability', 'able', 'abnormalities', 'abound', 'about', 'above', 'abrupt', 'absence', 'absent', 'absolute', 'absolutely', 'absorb', 'absorbed', 'absorbing', 'absorption', 'abstain', 'abstaining', 'abstention', 'abstract', 'abstraction', 'abstractions', 'abstracts', 'abundancy', 'abuse', 'ac', 'accelerate', 'accelerated', 'accelerating', 'acceleration', 'accelerometers', 'accept', 'acceptable', 'acceptance', 'accepted', 'access', 'accessed', 'accessible', 'acclaimed', 'accommodate', 'accommodates', 'accompanied', 'accompanying', 'accomplish', 'accomplished', 'accomplishes', 'accord', 'accordance', 'according', 'accordingly', 'account', 'accounted', 'accounting', 'accounts', 'accp', 'accumulate', 'accumulated', 'accumulation', 'accumulator', 'accuracies', 'accuracy', 'accurate', 'accurately', 'acetylcholine', 'achievable', 'achieve', 'achieved', 'achieves', 'achieving', 'acknowledges', 'acoustic', 'acoustics', 'acquire', 'acquired', 'acquiring', 'acquisition', 'across', 'acs', 'act', 'acterization', 'acting', 'action', 'actions', 'activated', 'activation', 'activations', 'active', 'actively', 'activities', 'activity', 'actor', 'actors', 'acts']\n",
            "['actual', 'actually', 'actuated', 'acyclic', 'ad', 'ada', 'adaboost', 'adap', 'adapt', 'adaptability', 'adaptation', 'adapted', 'adapting', 'adaptive', 'adaptively', 'adaptiveness', 'adaptivity', 'adaptor', 'adapts', 'add', 'added', 'adding', 'addition', 'additional', 'additionally', 'additions', 'additive', 'address', 'addressed', 'addresses', 'addressing', 'adds', 'adequacy', 'adequate', 'adequately', 'adhering', 'adjacency', 'adjacent', 'adjusted', 'adjusting', 'adjustment', 'adjustments', 'adjusts', 'adm', 'administered', 'admira', 'admissible', 'admit', 'admits', 'admixture', 'adni', 'ado', 'adolescent', 'adopt', 'adopted', 'adopting', 'adopts', 'adp', 'adress', 'adresses', 'ads', 'adults', 'advance', 'advanced', 'advancement', 'advances', 'advancing', 'advantage', 'advantageous', 'advantages', 'advent', 'adversarial', 'adversaries', 'adversary', 'adverse', 'advertisement', 'advertisers', 'advertising', 'advice', 'advised', 'advocate', 'advocated', 'aer', 'aesthetic', 'aesthetically', 'afd', 'affairs', 'affect', 'affected', 'affecting', 'affects', 'afferent', 'affine', 'affinities', 'affinity', 'affirmative', 'afforded', 'affords', 'aforementioned', 'aforesaid']\n",
            "['after', 'aftereffects', 'afterwards', 'again', 'against', 'age', 'agenda', 'agendas', 'agent', 'agents', 'agglomerate', 'agglomerative', 'aggregate', 'aggregated', 'aggregating', 'aggregation', 'aggressive', 'aggressively', 'agnostic', 'agnostically', 'ago', 'agorithm', 'agree', 'agreement', 'ahead', 'ahp', 'ai', 'aic', 'aid', 'aids', 'aim', 'aimed', 'aiming', 'aims', 'ais', 'akaike', 'akin', 'al', 'alarm', 'alarms', 'album', 'alcohol', 'alert', 'alexanders', 'algebra', 'algebraic', 'algo', 'algorithm', 'algorithmic', 'algorithmically', 'algorithms', 'aligned', 'aligning', 'alignment', 'alignments', 'aligns', 'alike', 'all', 'allay', 'alleviate', 'alleviated', 'alleviating', 'alligned', 'allocate', 'allocated', 'allocating', 'allocation', 'allow', 'allowed', 'allowing', 'allows', 'almost', 'alone', 'along', 'alongside', 'alpaca', 'alpha', 'alphabet', 'alphabets', 'alphai', 'already', 'also', 'alter', 'alteration', 'altered', 'altering', 'alternate', 'alternately', 'alternates', 'alternating', 'alternation', 'alternations', 'alternative', 'alternatively', 'alternatives', 'although', 'altogether', 'always', 'alzheimer', 'alzheimers']\n",
            "['am', 'amazon', 'ambient', 'ambiguities', 'ambiguity', 'ambiguous', 'ambitious', 'amenable', 'ammar', 'amoebe', 'among', 'amongst', 'amount', 'amounts', 'amp', 'ample', 'amplified', 'amplitude', 'amplitudes', 'an', 'analog', 'analogous', 'analogs', 'analogue', 'analogues', 'analogy', 'analyse', 'analysed', 'analyses', 'analysis', 'analysts', 'analytic', 'analytical', 'analytically', 'analyze', 'analyzed', 'analyzers', 'analyzes', 'analyzing', 'anatomic', 'anatomical', 'anatomically', 'ancestor', 'ancestral', 'anchor', 'anchored', 'anchoring', 'anchors', 'ancient', 'and', 'andor', 'anecdotal', 'anesthesia', 'anesthetized', 'anew', 'angle', 'angles', 'angular', 'animal', 'animals', 'anisotropic', 'anlysis', 'annealed', 'annealing', 'annotate', 'annotated', 'annotating', 'annotation', 'annotations', 'annotator', 'annotators', 'annual', 'anomalies', 'anomalous', 'anomaly', 'anonymize', 'another', 'anothers', 'answer', 'answers', 'ant', 'antagonistic', 'antennal', 'anterior', 'anthropomorphic', 'anticipate', 'anticipated', 'anticipative', 'anticipatory', 'antisense', 'antithetic', 'ants', 'any', 'anything', 'anytime', 'anyway', 'ap', 'apache', 'apart', 'aperture']\n",
            "['apiavi', 'aposteriori', 'apparatus', 'apparent', 'apparently', 'appeal', 'appealing', 'appear', 'appearance', 'appearances', 'appeared', 'appearing', 'appears', 'append', 'appled', 'appliances', 'applica', 'applicability', 'applicable', 'application', 'applications', 'applied', 'applies', 'apply', 'applying', 'apprentices', 'apprenticeship', 'approach', 'approached', 'approaches', 'approaching', 'approachs', 'approporiate', 'appropriate', 'appropriately', 'appropriateness', 'approximate', 'approximated', 'approximately', 'approximates', 'approximating', 'approximation', 'approximationbellman', 'approximations', 'approximator', 'approximators', 'ar', 'arabic', 'arate', 'arbiters', 'arbitrarily', 'arbitrary', 'architecture', 'architectures', 'arcones', 'ard', 'are', 'area', 'areas', 'arguably', 'argue', 'argued', 'argument', 'arguments', 'arise', 'arises', 'arising', 'arithmetic', 'arm', 'armax', 'armed', 'armp', 'arms', 'arora', 'around', 'arow', 'arranged', 'arrangement', 'array', 'arrays', 'arrival', 'arrive', 'arriving', 'art', 'arterial', 'article', 'articles', 'articulated', 'artifact', 'artifacts', 'artificial', 'artificially', 'artists', 'arts', 'ary', 'as', 'ascent', 'asing', 'ask', 'asked']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvLK5QhU0L34",
        "colab_type": "text"
      },
      "source": [
        "# Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sNXXnDEIGSV",
        "colab_type": "text"
      },
      "source": [
        "## Parameters configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQVt7zdjjH_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters configuration\n",
        "SEQUENCE_LENGTH = 100\n",
        "MAX_VOCAB_SIZE = n_unique_words\n",
        "EMBEDDING_DIM = 512\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfcHrPpINcK",
        "colab_type": "text"
      },
      "source": [
        "## Create sequences of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lII3wDDPjv9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sequences of words\n",
        "sequences_words = []\n",
        "for i in range(0, n_words - SEQUENCE_LENGTH):\n",
        "\ts = ' '.join(words[i:i+SEQUENCE_LENGTH])\n",
        "\tsequences_words.append(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb3-uI_ZIRbR",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfKBMQAY1a66",
        "colab_type": "code",
        "outputId": "a76e251c-1ea1-4352-8543-a37e99add995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=False)\n",
        "tokenizer.fit_on_texts(sequences_words)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# convert the sequences into integers\n",
        "sequences = tokenizer.texts_to_sequences(sequences_words)\n",
        "n_sequences = len(sequences)\n",
        "# vocabulary size\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "print(\"Number of unique tokens: \", len(word_index))\n",
        "print('Total number of sequences: %d' % n_sequences)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique tokens:  8897\n",
            "Total number of sequences: 228047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF-Gtu3TIVk-",
        "colab_type": "text"
      },
      "source": [
        "## Create input and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1pTRtLAmNDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create input and output \n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "\n",
        "y = to_categorical(y, num_classes = vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w9Ggx98E5G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training set and validation set\n",
        "def shuffle_train_test_split(X_all, y_all, shuffle=True, test_percent=20, random_state=10):\n",
        "    \n",
        "    if shuffle:\n",
        "      X_all_shuffled = []\n",
        "      y_all_shuffled = []\n",
        "      #for i in np.random.permutation(len(X_all)):\n",
        "      for i in np.random.RandomState(seed=random_state).permutation(len(X_all)):\n",
        "          X_all_shuffled.append(X_all[i])\n",
        "          y_all_shuffled.append(y_all[i])\n",
        "    else:\n",
        "      X_all_shuffled = X_all\n",
        "      y_all_shuffled = y_all\n",
        "\n",
        "    split_index = int(len(X_all) * (1.-(test_percent/100.)))\n",
        "    X_train, X_test = X_all_shuffled[:split_index], X_all_shuffled[split_index:]\n",
        "    y_train, y_test = y_all_shuffled[:split_index], y_all_shuffled[split_index:]\n",
        "    \n",
        "    X_train = np.array(X_train)    \n",
        "    y_train = np.array(y_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0tlc5noHHCz",
        "colab_type": "code",
        "outputId": "a7a9cdd2-04d1-4dbf-d0a1-4c4b89f2b918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "X_train, y_train, X_test, y_test = shuffle_train_test_split(X, y, test_percent=20)\n",
        "\n",
        "print(\"Shape of X training set: \", X_train.shape)\n",
        "print(\"Shape of y training set: \", y_train.shape)\n",
        "print(\"Shape of X test set: \", X_test.shape)\n",
        "print(\"Shape of y test set: \", y_test.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X training set:  (182437, 99)\n",
            "Shape of y training set:  (182437, 8898)\n",
            "Shape of X test set:  (45610, 99)\n",
            "Shape of y test set:  (45610, 8898)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFAeJpNWwxdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU9G9d3f7PcA",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwJUxLue7XaN",
        "colab_type": "text"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3u8x8lX5jg3",
        "colab_type": "code",
        "outputId": "dba0bd54-f6bc-43b1-eb56-1a1fc9c9e0a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=SEQUENCE_LENGTH-1))\n",
        "model.add(Bidirectional(LSTM(128))) # the last LSTM layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fbb8ccc5e80>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fbb8e599f60>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 99, 512)           4555776   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               656384    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8898)              2286786   \n",
            "=================================================================\n",
            "Total params: 7,498,946\n",
            "Trainable params: 7,498,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXKGPrQ8-gL5",
        "colab_type": "text"
      },
      "source": [
        "## Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCEmLVPp-hqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaFcd95r-7tD",
        "colab_type": "text"
      },
      "source": [
        "## Define the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gnJCiEb-9C_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = \"model_weights_epoch{epoch:03d}_loss{loss:.4f}_acc{accuracy:.4f}_val_loss{val_loss:.4f}_val_acc{val_accuracy:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "callbacks_list = [checkpoint, early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW5XlkgjAuLp",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__8CsMnAPMci",
        "colab_type": "code",
        "outputId": "7ae39a43-9b09-4374-b309-ab0b48acdeff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          batch_size = BATCH_SIZE, \n",
        "          epochs = EPOCHS, \n",
        "          callbacks = callbacks_list,\n",
        "          validation_data = (X_test, y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 182437 samples, validate on 45610 samples\n",
            "Epoch 1/10\n",
            "182432/182437 [============================>.] - ETA: 0s - loss: 5.8152 - accuracy: 0.1586\n",
            "Epoch 00001: loss improved from inf to 5.81527, saving model to model_weights_epoch001_loss5.8153_acc0.1586_val_loss5.3607_val_acc0.2009.hdf5\n",
            "182437/182437 [==============================] - 321s 2ms/sample - loss: 5.8153 - accuracy: 0.1586 - val_loss: 5.3607 - val_accuracy: 0.2009\n",
            "Epoch 2/10\n",
            "182432/182437 [============================>.] - ETA: 0s - loss: 5.0487 - accuracy: 0.2172\n",
            "Epoch 00002: loss improved from 5.81527 to 5.04876, saving model to model_weights_epoch002_loss5.0488_acc0.2172_val_loss5.1478_val_acc0.2231.hdf5\n",
            "182437/182437 [==============================] - 319s 2ms/sample - loss: 5.0488 - accuracy: 0.2172 - val_loss: 5.1478 - val_accuracy: 0.2231\n",
            "Epoch 3/10\n",
            "182432/182437 [============================>.] - ETA: 0s - loss: 4.5998 - accuracy: 0.2467\n",
            "Epoch 00003: loss improved from 5.04876 to 4.59972, saving model to model_weights_epoch003_loss4.5997_acc0.2467_val_loss5.1176_val_acc0.2320.hdf5\n",
            "182437/182437 [==============================] - 317s 2ms/sample - loss: 4.5997 - accuracy: 0.2467 - val_loss: 5.1176 - val_accuracy: 0.2320\n",
            "Epoch 4/10\n",
            "182432/182437 [============================>.] - ETA: 0s - loss: 4.1712 - accuracy: 0.2777\n",
            "Epoch 00004: loss improved from 4.59972 to 4.17121, saving model to model_weights_epoch004_loss4.1712_acc0.2777_val_loss5.1799_val_acc0.2272.hdf5\n",
            "182437/182437 [==============================] - 317s 2ms/sample - loss: 4.1712 - accuracy: 0.2777 - val_loss: 5.1799 - val_accuracy: 0.2272\n",
            "Epoch 5/10\n",
            "182400/182437 [============================>.] - ETA: 0s - loss: 3.7446 - accuracy: 0.3142\n",
            "Epoch 00005: loss improved from 4.17121 to 3.74464, saving model to model_weights_epoch005_loss3.7446_acc0.3142_val_loss5.3041_val_acc0.2253.hdf5\n",
            "182437/182437 [==============================] - 320s 2ms/sample - loss: 3.7446 - accuracy: 0.3142 - val_loss: 5.3041 - val_accuracy: 0.2253\n",
            "Epoch 6/10\n",
            "182432/182437 [============================>.] - ETA: 0s - loss: 3.3490 - accuracy: 0.3570\n",
            "Epoch 00006: loss improved from 3.74464 to 3.34899, saving model to model_weights_epoch006_loss3.3490_acc0.3570_val_loss5.4270_val_acc0.2200.hdf5\n",
            "182437/182437 [==============================] - 321s 2ms/sample - loss: 3.3490 - accuracy: 0.3570 - val_loss: 5.4270 - val_accuracy: 0.2200\n",
            "Epoch 7/10\n",
            "182432/182437 [============================>.] - ETA: 0s - loss: 2.9951 - accuracy: 0.4032\n",
            "Epoch 00007: loss improved from 3.34899 to 2.99519, saving model to model_weights_epoch007_loss2.9952_acc0.4032_val_loss5.5744_val_acc0.2146.hdf5\n",
            "182437/182437 [==============================] - 320s 2ms/sample - loss: 2.9952 - accuracy: 0.4032 - val_loss: 5.5744 - val_accuracy: 0.2146\n",
            "Epoch 8/10\n",
            "182400/182437 [============================>.] - ETA: 0s - loss: 2.6957 - accuracy: 0.4462\n",
            "Epoch 00008: loss improved from 2.99519 to 2.69578, saving model to model_weights_epoch008_loss2.6958_acc0.4462_val_loss5.7098_val_acc0.2085.hdf5\n",
            "182437/182437 [==============================] - 316s 2ms/sample - loss: 2.6958 - accuracy: 0.4462 - val_loss: 5.7098 - val_accuracy: 0.2085\n",
            "Epoch 9/10\n",
            "182432/182437 [============================>.] - ETA: 0s - loss: 2.4362 - accuracy: 0.4878\n",
            "Epoch 00009: loss improved from 2.69578 to 2.43628, saving model to model_weights_epoch009_loss2.4363_acc0.4878_val_loss5.8397_val_acc0.2022.hdf5\n",
            "182437/182437 [==============================] - 317s 2ms/sample - loss: 2.4363 - accuracy: 0.4878 - val_loss: 5.8397 - val_accuracy: 0.2022\n",
            "Epoch 10/10\n",
            "182432/182437 [============================>.] - ETA: 0s - loss: 2.2174 - accuracy: 0.5210\n",
            "Epoch 00010: loss improved from 2.43628 to 2.21742, saving model to model_weights_epoch010_loss2.2174_acc0.5210_val_loss5.9626_val_acc0.1983.hdf5\n",
            "182437/182437 [==============================] - 318s 2ms/sample - loss: 2.2174 - accuracy: 0.5210 - val_loss: 5.9626 - val_accuracy: 0.1983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbb8be9cf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seN4D8PfESAX",
        "colab_type": "text"
      },
      "source": [
        "# Output details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JEs3LtFvNy1",
        "colab_type": "code",
        "outputId": "7b205aca-cc5e-441b-cb41-0d76ed3786e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Get the output of a layer\n",
        "# embedding\n",
        "get_layer_output0 = backend.function(inputs = model.input, outputs = model.layers[0].output)\n",
        "layer_output0 = get_layer_output0(sequences[:5])\n",
        "# lstm\n",
        "get_layer_output1 = backend.function(inputs = model.input, outputs = model.layers[1].output)\n",
        "layer_output1 = get_layer_output1(sequences[:5])\n",
        "# dropout\n",
        "get_layer_output2 = backend.function(inputs = model.input, outputs = model.layers[2].output)\n",
        "layer_output2 = get_layer_output1(sequences[:5])\n",
        "# dense\n",
        "get_layer_output3 = backend.function(inputs = model.input, outputs = model.layers[3].output)\n",
        "layer_output3 = get_layer_output1(sequences[:5])\n",
        "\n",
        "print(\"layer: \", model.layers[0])\n",
        "print(\"layer output: \", layer_output0)\n",
        "print(\"layer: \", model.layers[1])\n",
        "print(\"layer output: \", layer_output1)\n",
        "print(\"layer: \", model.layers[2])\n",
        "print(\"layer output: \", layer_output2)\n",
        "print(\"layer: \", model.layers[3])\n",
        "print(\"layer output: \", layer_output3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer:  <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7fbb8cc42ac8>\n",
            "layer output:  [[[ 0.20554519  0.20288983  0.19393457 ... -0.0007705   0.04818037\n",
            "   -0.15278658]\n",
            "  [-0.03763249  0.4043907   0.14942177 ...  0.11484479 -0.5528995\n",
            "    0.45601395]\n",
            "  [ 0.02235835 -0.16450481  0.22147314 ...  0.0764342   0.17384566\n",
            "    0.26113456]\n",
            "  ...\n",
            "  [ 0.1155671  -0.08567201  0.42066222 ... -0.17167073  0.16942848\n",
            "   -0.26238167]\n",
            "  [-0.09397724 -0.06511106 -0.21372493 ...  0.70120984  0.24664584\n",
            "   -0.04742411]\n",
            "  [ 0.00174669 -0.19702174 -0.20141216 ...  0.2795064   0.05864049\n",
            "   -0.10383115]]\n",
            "\n",
            " [[-0.03763249  0.4043907   0.14942177 ...  0.11484479 -0.5528995\n",
            "    0.45601395]\n",
            "  [ 0.02235835 -0.16450481  0.22147314 ...  0.0764342   0.17384566\n",
            "    0.26113456]\n",
            "  [ 0.05065278  0.10408973  0.33159038 ...  0.47294742 -0.16465123\n",
            "    0.06863154]\n",
            "  ...\n",
            "  [-0.09397724 -0.06511106 -0.21372493 ...  0.70120984  0.24664584\n",
            "   -0.04742411]\n",
            "  [ 0.00174669 -0.19702174 -0.20141216 ...  0.2795064   0.05864049\n",
            "   -0.10383115]\n",
            "  [ 0.39888725 -0.72240037 -0.56028974 ... -0.21908966 -0.12352631\n",
            "   -0.18970588]]\n",
            "\n",
            " [[ 0.02235835 -0.16450481  0.22147314 ...  0.0764342   0.17384566\n",
            "    0.26113456]\n",
            "  [ 0.05065278  0.10408973  0.33159038 ...  0.47294742 -0.16465123\n",
            "    0.06863154]\n",
            "  [ 0.2340966   0.23810153 -0.23168196 ...  0.30621243  0.09044719\n",
            "    0.10161848]\n",
            "  ...\n",
            "  [ 0.00174669 -0.19702174 -0.20141216 ...  0.2795064   0.05864049\n",
            "   -0.10383115]\n",
            "  [ 0.39888725 -0.72240037 -0.56028974 ... -0.21908966 -0.12352631\n",
            "   -0.18970588]\n",
            "  [-0.25258663 -0.07328802 -0.11810212 ...  0.00950293 -0.09965868\n",
            "   -0.26287824]]\n",
            "\n",
            " [[ 0.05065278  0.10408973  0.33159038 ...  0.47294742 -0.16465123\n",
            "    0.06863154]\n",
            "  [ 0.2340966   0.23810153 -0.23168196 ...  0.30621243  0.09044719\n",
            "    0.10161848]\n",
            "  [ 0.23453464  0.02375309  0.19277833 ... -0.06766187  0.58834296\n",
            "   -0.021005  ]\n",
            "  ...\n",
            "  [ 0.39888725 -0.72240037 -0.56028974 ... -0.21908966 -0.12352631\n",
            "   -0.18970588]\n",
            "  [-0.25258663 -0.07328802 -0.11810212 ...  0.00950293 -0.09965868\n",
            "   -0.26287824]\n",
            "  [-0.04378894 -0.0534263  -0.0959979  ...  0.5044338  -0.28381228\n",
            "   -0.37793207]]\n",
            "\n",
            " [[ 0.2340966   0.23810153 -0.23168196 ...  0.30621243  0.09044719\n",
            "    0.10161848]\n",
            "  [ 0.23453464  0.02375309  0.19277833 ... -0.06766187  0.58834296\n",
            "   -0.021005  ]\n",
            "  [-0.09713266 -0.08154852  0.3304558  ... -0.08020283  0.03029915\n",
            "    0.49894217]\n",
            "  ...\n",
            "  [-0.25258663 -0.07328802 -0.11810212 ...  0.00950293 -0.09965868\n",
            "   -0.26287824]\n",
            "  [-0.04378894 -0.0534263  -0.0959979  ...  0.5044338  -0.28381228\n",
            "   -0.37793207]\n",
            "  [ 0.28971344  0.06333099 -0.04442856 ... -0.03797781  0.22617984\n",
            "   -0.08957984]]]\n",
            "layer:  <tensorflow.python.keras.layers.wrappers.Bidirectional object at 0x7fbb8e5998d0>\n",
            "layer output:  [[-7.4866724e-01  9.3392380e-02 -5.0069254e-02 ...  5.7458574e-01\n",
            "   9.3238378e-01 -9.0126204e-01]\n",
            " [-2.7342588e-01  5.4087036e-04 -6.0464913e-01 ... -4.8929765e-03\n",
            "   5.4416317e-01 -5.1023030e-01]\n",
            " [-7.8089756e-01  4.0302327e-04 -6.5559953e-01 ...  3.0058439e-04\n",
            "   1.9843582e-02 -1.2420920e-01]\n",
            " [-7.1246141e-01  6.7042492e-02  3.5391289e-01 ... -4.2369565e-01\n",
            "   8.2437620e-02 -1.4031559e-03]\n",
            " [ 7.8546733e-02  1.1311619e-01  2.2944550e-01 ... -1.1994105e-02\n",
            "  -8.2746387e-01 -5.1694548e-01]]\n",
            "layer:  <tensorflow.python.keras.layers.core.Dropout object at 0x7fbb8ccccc18>\n",
            "layer output:  [[-7.4866724e-01  9.3392380e-02 -5.0069254e-02 ...  5.7458574e-01\n",
            "   9.3238378e-01 -9.0126204e-01]\n",
            " [-2.7342588e-01  5.4087036e-04 -6.0464913e-01 ... -4.8929765e-03\n",
            "   5.4416317e-01 -5.1023030e-01]\n",
            " [-7.8089756e-01  4.0302327e-04 -6.5559953e-01 ...  3.0058439e-04\n",
            "   1.9843582e-02 -1.2420920e-01]\n",
            " [-7.1246141e-01  6.7042492e-02  3.5391289e-01 ... -4.2369565e-01\n",
            "   8.2437620e-02 -1.4031559e-03]\n",
            " [ 7.8546733e-02  1.1311619e-01  2.2944550e-01 ... -1.1994105e-02\n",
            "  -8.2746387e-01 -5.1694548e-01]]\n",
            "layer:  <tensorflow.python.keras.layers.core.Dense object at 0x7fbb8e562780>\n",
            "layer output:  [[-7.4866724e-01  9.3392380e-02 -5.0069254e-02 ...  5.7458574e-01\n",
            "   9.3238378e-01 -9.0126204e-01]\n",
            " [-2.7342588e-01  5.4087036e-04 -6.0464913e-01 ... -4.8929765e-03\n",
            "   5.4416317e-01 -5.1023030e-01]\n",
            " [-7.8089756e-01  4.0302327e-04 -6.5559953e-01 ...  3.0058439e-04\n",
            "   1.9843582e-02 -1.2420920e-01]\n",
            " [-7.1246141e-01  6.7042492e-02  3.5391289e-01 ... -4.2369565e-01\n",
            "   8.2437620e-02 -1.4031559e-03]\n",
            " [ 7.8546733e-02  1.1311619e-01  2.2944550e-01 ... -1.1994105e-02\n",
            "  -8.2746387e-01 -5.1694548e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kFsZo9p66MS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "dfd1f0dc-75cc-4dce-d845-51bf47298293"
      },
      "source": [
        "# Plot train and validation curves\n",
        "fig = plt.figure()\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2u1h+be9cykAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LGLhLo1FftW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}