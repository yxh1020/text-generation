{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aazu25up6FBb"
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B46pOmSq6IgD"
   },
   "outputs": [],
   "source": [
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdpLrSTi8Ajg"
   },
   "source": [
    "# Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54914,
     "status": "ok",
     "timestamp": 1573601576890,
     "user": {
      "displayName": "Yuan Hu",
      "photoUrl": "",
      "userId": "14204862805009818583"
     },
     "user_tz": 480
    },
    "id": "E9vJhsm08B33",
    "outputId": "f0f95084-bf66-446b-8abd-23264b305d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "gpt2.mount_gdrive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qsHzd9165530"
   },
   "source": [
    "# Load a Trained Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVcT5KJv5Zdl"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80316,
     "status": "ok",
     "timestamp": 1573601602311,
     "user": {
      "displayName": "Yuan Hu",
      "photoUrl": "",
      "userId": "14204862805009818583"
     },
     "user_tz": 480
    },
    "id": "Cp3Z-jk457Ar",
    "outputId": "1d94a0ef-6a8f-4f41-b569-8de45bdf15d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-3000\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-3000\n"
     ]
    }
   ],
   "source": [
    "# load the retrained model checkpoint + metadata necessary to generate text\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JSosz_1n7JkY"
   },
   "source": [
    "# Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCSHqPjZ7bXw"
   },
   "outputs": [],
   "source": [
    "seed = \"in deep neural nets, lower level embedding layers account for a large portion of the total number of parameters.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85421,
     "status": "ok",
     "timestamp": 1573601607433,
     "user": {
      "displayName": "Yuan Hu",
      "photoUrl": "",
      "userId": "14204862805009818583"
     },
     "user_tz": 480
    },
    "id": "N-cpEy8j7LU1",
    "outputId": "c94678bd-5dcd-46d2-87d2-f4df969e5f15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in deep neural nets, lower level embedding layers account for a large portion of the total number of parameters. we propose a framework based on recurrent neural networks for interpretable dropout distributions . in particular , we construct an interpretable disjoint set of dropout representations , each representing a subset of the input variables via a skip connection , and evaluate them on three datasets . interpretability of the dropout distributions is proved via extensive simulations .\n",
      "this work introduces a novel analysis of the definitions of proximal operators used in majority of gradient descent related problems . for all such definitions , we report the convergence rates of\n",
      "====================\n",
      "in deep neural nets, lower level embedding layers account for a large portion of the total number of parameters. these lower level embeddings , however , are trained by a single global objective , and the number of parameters to learn is limited . in many applications , several layers can be jointly trained , each of which may employ fewer parameters than the initial output . in this paper , we describe a unified approach that simultaneously improves the parameters of both layers and improves the learned layer . the resulting unified approach learns the lower level embeddings jointly , and jointly determines the number of parameters for which the original output layer can\n",
      "====================\n",
      "in deep neural nets, lower level embedding layers account for a large portion of the total number of parameters. we propose a simple network architecture that integrates these lower level representations in a simple way . our proposed network uses feedforward connections to make split passes over input pairs to reconstruct the embedding vectors . we evaluate our method on image and text classification tasks .\n",
      "the boosting problem is known to be np hard in the ai setting as it is np hard in both the standard and exponential setting and , as such , can only be convexized as a linear program . in this paper , we propose the soft\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              length=100, # default 1023, the maximum\n",
    "              temperature=0.7,\n",
    "              prefix=seed,\n",
    "              nsamples=3,\n",
    "              batch_size=3\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gpt2_generate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
