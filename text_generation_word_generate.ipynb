{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_word_generate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBgCpXRXgXX4",
        "colab_type": "text"
      },
      "source": [
        "# Mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VacojtMUgaHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow--gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MluSWRHbgduf",
        "colab_type": "code",
        "outputId": "12f892fe-b9b7-415a-ee7a-96ca55d07965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrlBmhtagoh5",
        "colab_type": "text"
      },
      "source": [
        "# Load modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSb4-S1itSGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pickle import load\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPABPh1Lh8xm",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozwrz9ygWKaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/text-generation/text-generation-word/model01/model_small.h5')\n",
        "# load the tokenizer\n",
        "tokenizer = load(open('/content/drive/My Drive/Colab Notebooks/text-generation/text-generation-word/model01/tokenizer_small.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM4DI6sAO8zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load sequences from file\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/text-generation/text-generation-word/model01/sequences_words_small.txt\", 'r') as file:\n",
        "  text_file = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ4pSGoEk8xs",
        "colab_type": "text"
      },
      "source": [
        "# Generate sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70wukEgziIVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_words = text_file.split('\\n')\n",
        "SEQUENCE_LENGTH = len(sequences_words[0].split()) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsKSmWBwvUHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def sequence_generator(model, tokenizer, seq_length, seed_text, n_words):\n",
        "  seed_text = seed_text.lower()\n",
        "  result = []\n",
        "  word_index = tokenizer.word_index\n",
        "  text_ip = seed_text\n",
        "\t\n",
        "  for _ in range(n_words):\n",
        "    # tokenization\n",
        "    sequences = tokenizer.texts_to_sequences([text_ip])[0]\n",
        "    # truncate sequences to a fixed length\n",
        "    sequences = pad_sequences([sequences], maxlen=seq_length, truncating='pre')\n",
        "    # predict probabilities for each word\n",
        "    y_predict = model.predict_classes(sequences, verbose=0)\n",
        "    # map word index to word\n",
        "    word_op = ''\n",
        "    for word, index in word_index.items():\n",
        "      if index == y_predict:\n",
        "        word_op = word\n",
        "        break\n",
        "\t\t# update text input\n",
        "    text_ip += ' ' + word_op\n",
        "    \n",
        "    result.append(word_op)\n",
        "  return ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CmEQSEeQH83",
        "colab_type": "code",
        "outputId": "4b273890-0239-442a-b680-a05e3a75c8b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# select a seed text from corpus\n",
        "seed_text = sequences_words[randint(0,len(sequences_words))]\n",
        "print(seed_text + '\\n')\n",
        "generated = sequence_generator(model, tokenizer, SEQUENCE_LENGTH, seed_text, 30)\n",
        "print(generated)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sblsh also provides an unbiased estimate of angular similarity , yet with a smaller variance when the angle to estimate is within retrieval experiments . sudderth , wainwright , and willsky conjectured that the bethe approximation corresponding to any fixed point of the belief propagation algorithm over an attractive , pairwise binary graphical model provides a lower bound on the true partition function . in this work , we resolve this conjecture in the affirmative by demonstrating that , for any graphical model with binary variables whose potential functions are all log supermodular , the bethe partition function always lower\n",
            "\n",
            "bounds . we propose a novel task for computing group lasso , randomly embedding from the current state of the art . we extend the notion of a family of\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMuVLZ_-Aoxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "eb9375d4-1547-4ee7-868e-d54c67ad2ea2"
      },
      "source": [
        "# a random text\n",
        "seed_text_random = \"A pool of handwritten signatures is used to train a neural network for the task of deciding whether or not a given signature is a forgery. \"\n",
        "print(seed_text_random + '\\n')\n",
        "generated = sequence_generator(model, tokenizer, SEQUENCE_LENGTH, seed_text_random, 30)\n",
        "print(generated)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A pool of handwritten signatures is used to train a neural network for the task of deciding whether or not a given signature is a forgery. \n",
            "\n",
            "fixed sample of the size of the furthermore . we focus on the task of selecting two standard benchmark problems with both benchmark datasets , and times we show that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOn521PikPJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}